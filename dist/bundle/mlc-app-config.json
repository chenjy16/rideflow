{
  "model_list": [
    {
      "model_id": "Llama-3.2-3B-Instruct-q4f16_1-MLC",
      "model_lib": "llama_q4f16_1_d44304359a2802d16aa168086928bcad",
      "model_path": "Llama-3.2-3B-Instruct-q4f16_1-MLC",
      "estimated_vram_bytes": 3000000000,
      "display_name": "AI Route Planning"
    },
    {
      "model_id": "gemma-2-2b-q4f16_1-MLC",
      "model_lib": "gemma2_q4f16_1_779a95d4ef785ea159992d38fac2317f",
      "model_url": "https://huggingface.co/mlc-ai/gemma-2-2b-it-q4f16_1-MLC",
      "estimated_vram_bytes": 3000000000,
      "display_name": "AI Route Planning 1"
    },
    {
      "model_id": "Phi-3.5-mini-instruct-q4f16_1-MLC",
      "model_lib": "phi3_q4f16_1_eba3d93dab5930b68f7296c1fd0d29ec",
      "model_url": "https://huggingface.co/mlc-ai/Phi-3.5-mini-instruct-q4f16_1-MLC",
      "estimated_vram_bytes": 3043000000,
      "display_name": "AI Route Planning 2"
    },
    {
      "model_id": "Qwen2.5-1.5B-Instruct-q4f16_1-MLC",
      "model_lib": "qwen2_q4f16_1_11da1300cac0945ff40dfee7b8c81b68",
      "model_url": "https://huggingface.co/mlc-ai/Qwen2.5-1.5B-Instruct-q4f16_1-MLC",
      "estimated_vram_bytes": 2960000000,
      "display_name": "AI Route Planning 3"
    }
  ]
}

